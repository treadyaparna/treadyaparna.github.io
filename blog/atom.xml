<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://treadyaparna.github.io/blog</id>
    <title>Aparna Saha Blog</title>
    <updated>2025-10-10T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://treadyaparna.github.io/blog"/>
    <subtitle>Aparna Saha Blog</subtitle>
    <entry>
        <title type="html"><![CDATA[Distributed Data Stream Aggregator with AWS Step Functions]]></title>
        <id>https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator</id>
        <link href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator"/>
        <updated>2025-10-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[A comprehensive Distributed Data Stream Aggregator workflow that demonstrates large-scale data aggregation from multiple third-party locations using AWS Step Functions' distributed processing capabilities.]]></summary>
        <content type="html"><![CDATA[<p>A comprehensive <strong>Distributed Data Stream Aggregator</strong> workflow that demonstrates large-scale data aggregation from multiple third-party locations using AWS Step Functions' distributed processing capabilities.</p>
<p>A key highlight of this solution is its <strong>unique no-Lambda approach</strong>, making it a <strong>low-code (almost no-code)</strong> architecture — with minimal coding required only in the AWS Glue job for final consolidation.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">​</a></h2>
<p>When working at scale, coordinating the ingestion of data from many external APIs — with pagination, retries, rate limits, and large payloads — gets complicated fast. The typical solution often leans heavily on AWS Lambda, which brings its own operational and scaling burdens.</p>
<p>This post walks through a new, Lambda-free pattern contributed to the <a href="https://github.com/aws-samples/step-functions-workflows-collection/pull/404" target="_blank" rel="noopener noreferrer">AWS Step Functions Workflows Collection</a>: a <strong>three-tier, distributed data aggregator</strong> using Step Functions (standard + express), S3, Glue, and DynamoDB. You’ll see how to orchestrate high fan-out, handle payload limits, and maintain observability — all with minimal custom code.</p>
<p>I’ll cover:</p>
<ul>
<li>The overall architecture and rationale</li>
<li>How each tier works (orchestrator, express children, aggregation)</li>
<li>Key AWS Step Functions configurations (Distributed Map, concurrency, error handling)</li>
<li>Tradeoffs, best practices, and when to use this pattern</li>
</ul>
<p>By the end, you’ll have a blueprint you can adapt for your own large-scale data-aggregation use cases.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="solution-overview--motivation">Solution Overview &amp; Motivation<a href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator#solution-overview--motivation" class="hash-link" aria-label="Direct link to Solution Overview &amp; Motivation" title="Direct link to Solution Overview &amp; Motivation" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-problem-space">The Problem Space<a href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator#the-problem-space" class="hash-link" aria-label="Direct link to The Problem Space" title="Direct link to The Problem Space" translate="no">​</a></h3>
<p>Suppose you manage hundreds of locations or entities, and for each one you need to call multiple external APIs (each with pagination, retries, rate limits) and aggregate a combined dataset. You also expect that the result for a single location might exceed Step Functions’ 256 KB state payload limit (so you can’t carry full results inline).</p>
<p>Many teams solve this with a web of Lambda functions:</p>
<ol>
<li>Lambda A fans out tasks</li>
<li>Lambda B handles HTTP calls + pagination</li>
<li>Lambda C aggregates results</li>
<li>Etc.</li>
</ol>
<p>This introduces more code, more error surfaces, and scaling headaches.</p>
<p>What if you could move more logic into Step Functions itself, let AWS handle the orchestration, and offload heavy work to managed services (S3, Glue) — with <strong>zero Lambda</strong>?</p>
<p>That’s exactly what this new workflow achieves.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="architecture-at-a-glance">Architecture at a Glance<a href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator#architecture-at-a-glance" class="hash-link" aria-label="Direct link to Architecture at a Glance" title="Direct link to Architecture at a Glance" translate="no">​</a></h3>
<p><img decoding="async" loading="lazy" alt="Illustration" src="https://treadyaparna.github.io/assets/images/2025-10-01-distributed-data-stream-aggregator-illustration-66a7465d60610c3539a8ed6d9603f638.png" width="1920" height="1080" class="img_ev3q"></p>
<p>Here’s the high-level flow:</p>
<!-- -->
<ul>
<li>The <strong>orchestrator</strong> acts as the parent state machine (Standard mode).</li>
<li>It uses <strong>Distributed Map</strong> to iterate over “containers” (e.g. location or entity).</li>
<li>For each item, an <strong>Express child state machine</strong> is invoked to perform HTTP API calls, pagination, and write partial results to S3.</li>
<li>Once all child executions complete, the orchestrator triggers a <strong>Glue job</strong> to merge partial outputs into a final consolidated dataset.</li>
<li>A <strong>DynamoDB table</strong> tracks status, metrics, and metadata.</li>
</ul>
<p>Because partial results live in S3 (not in Step Functions’ state), I avoid payload size limits and keep orchestration logic lightweight.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-it-works-step-by-step">How It Works: Step by Step<a href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator#how-it-works-step-by-step" class="hash-link" aria-label="Direct link to How It Works: Step by Step" title="Direct link to How It Works: Step by Step" translate="no">​</a></h2>
<p>Let’s dive into each part of the workflow in more detail, along with key configurations.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-parent-orchestrator--distributed-map">1. Parent Orchestrator + Distributed Map<a href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator#1-parent-orchestrator--distributed-map" class="hash-link" aria-label="Direct link to 1. Parent Orchestrator + Distributed Map" title="Direct link to 1. Parent Orchestrator + Distributed Map" translate="no">​</a></h3>
<p>The parent state machine is implemented in <strong>Standard</strong> Step Functions mode. Its key job is to fan out work using a <strong>Distributed Map</strong> state. Because I adopt the distributed mode, the state machine does <em>not</em> manage all iterations internally — that offloads scale to AWS.</p>
<p>Here’s a representative snippet:</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"Type"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"Map"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"Label"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"IterateContainers"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"ItemProcessor"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"ProcessorConfig"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Mode"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"DISTRIBUTED"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"MaxConcurrency"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"ItemSelector"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"container.$"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"$.container"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"Iterator"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"StartAt"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"StartExpressChild"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre></div></div>
<ul>
<li><code>Mode: DISTIBUTED</code> tells Step Functions to spawn independent child executions per item.</li>
<li><code>MaxConcurrency</code> (e.g. set to 5) throttles how many child executions run in parallel, helping avoid overwhelming external APIs.</li>
<li>Each child receives one “container” item (e.g. a location or entity) to process.</li>
</ul>
<p>After the Map completes, the parent moves on to aggregation and status update steps (e.g. calling Glue, writing to DynamoDB).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-express-child-workflows-data-fetch--pagination">2. Express Child Workflows: Data Fetch &amp; Pagination<a href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator#2-express-child-workflows-data-fetch--pagination" class="hash-link" aria-label="Direct link to 2. Express Child Workflows: Data Fetch &amp; Pagination" title="Direct link to 2. Express Child Workflows: Data Fetch &amp; Pagination" translate="no">​</a></h3>
<p>Each Express child workflow is responsible for:</p>
<ul>
<li>Making HTTP (or other) API calls</li>
<li>Handling pagination (if the API returns a “next page” token)</li>
<li>Retrying on transient errors (with exponential backoff)</li>
<li>Writing partial results to S3</li>
<li>Returning a small summary to the parent</li>
</ul>
<p>Because Express workflows are lightweight and ephemeral, they’re ideal for short-lived data-fetch tasks. But because they’re “express”, they don’t offer exactly the same durability guarantees as Standard — so design accordingly (e.g. idempotency, retries, monitoring).</p>
<p>A simplified flow inside an Express child might look like:</p>
<ol>
<li>
<p>Call API endpoint</p>
</li>
<li>
<p>Check for <code>nextPageToken</code></p>
<ul>
<li>If yes, loop / re-enter the state</li>
<li>If no, finish</li>
</ul>
</li>
<li>
<p>Accumulate or write result chunk(s) to S3</p>
</li>
<li>
<p>Return a small metadata payload (e.g. record count, S3 key)</p>
</li>
</ol>
<p>Because full datasets for a container may be large, the child never returns full data in the Step Functions state. Instead, it writes into S3 — e.g. <code>s3://bucket/jobID/containerX.json</code>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-aggregation-via-glue">3. Aggregation via Glue<a href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator#3-aggregation-via-glue" class="hash-link" aria-label="Direct link to 3. Aggregation via Glue" title="Direct link to 3. Aggregation via Glue" translate="no">​</a></h3>
<p>Once all Express children complete, the orchestrator triggers an AWS Glue job. Its responsibility:</p>
<ul>
<li>Scan the “job prefix” in S3 (e.g. <code>s3://bucket/jobID/</code>)</li>
<li>Read all partial files</li>
<li>Merge / union them into a final dataset</li>
<li>Write out a consolidated result (e.g. JSON, Parquet, CSV)</li>
</ul>
<p>This offloads heavy merging/aggregation out of Step Functions and into Glue, which is built for data processing scale.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="4-status-tracking-with-dynamodb">4. Status Tracking with DynamoDB<a href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator#4-status-tracking-with-dynamodb" class="hash-link" aria-label="Direct link to 4. Status Tracking with DynamoDB" title="Direct link to 4. Status Tracking with DynamoDB" translate="no">​</a></h3>
<p>Parallel to Glue, or after Glue completes, orchestrator writes execution metadata into a <strong>DynamoDB</strong> table. Fields typically include:</p>
<ul>
<li>Job ID</li>
<li>Start / end timestamps</li>
<li>Number of containers processed</li>
<li>Number of records aggregated</li>
<li>Status (succeeded / failed / partial)</li>
<li>Retry counters or error messages</li>
</ul>
<p>This gives you an external, queryable log of workflow runs beyond the Step Functions execution history.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-this-pattern-matters">Why This Pattern Matters<a href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator#why-this-pattern-matters" class="hash-link" aria-label="Direct link to Why This Pattern Matters" title="Direct link to Why This Pattern Matters" translate="no">​</a></h2>
<p>Let’s compare this approach to a more traditional Lambda-centric pattern, and see why this might be a better fit in many cases.</p>
<table><thead><tr><th>Challenge / Constraint</th><th>Traditional Lambda-Driven Approach</th><th>This No-Lambda Distributed Pattern</th></tr></thead><tbody><tr><td>Payload size limits</td><td>Often need to chunk or stream through Lambda</td><td>Results are stored in S3, not carried in state</td></tr><tr><td>Lambda code maintenance</td><td>You write and maintain dozens of functions</td><td>Minimal or zero custom code (just config + glue script)</td></tr><tr><td>Scaling &amp; orchestration</td><td>You must manage concurrency, cold starts</td><td>Step Functions + Distributed Map abstracts much orchestration</td></tr><tr><td>Fault isolation</td><td>Failures in one Lambda might affect others</td><td>Each child is isolated; individual retries possible</td></tr><tr><td>Cost model</td><td>You pay for Lambda execution time per invocation</td><td>You pay for state transitions, Glue job, and S3 access</td></tr><tr><td>Observability</td><td>You need to build logging/tracing across Lambdas</td><td>Step Functions gives built-in visibility; DynamoDB logs augment it</td></tr></tbody></table>
<p>This pattern is especially suited when:</p>
<ul>
<li>You have <strong>many entities or containers</strong> to fetch in parallel</li>
<li>Data per container can be large (bigger than 256 KB)</li>
<li>You prefer <strong>infrastructure as configuration</strong> over custom code</li>
<li>You want to minimize the Lambda surface area</li>
</ul>
<p>That said, it’s not a silver bullet — which leads us to tradeoffs and things to watch out for.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="tradeoffs--design-considerations">Tradeoffs &amp; Design Considerations<a href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator#tradeoffs--design-considerations" class="hash-link" aria-label="Direct link to Tradeoffs &amp; Design Considerations" title="Direct link to Tradeoffs &amp; Design Considerations" translate="no">​</a></h2>
<ol>
<li>
<p><strong>Express vs Standard Workflows</strong>
Express workflows are fast and cost-efficient, but with lower execution duration and less durability guarantees. If your data fetch tasks are long-running or mission-critical, consider Standard children (though that complicates concurrency and cost).</p>
</li>
<li>
<p><strong>Glue Cold Starts and Overheads</strong>
Glue adds latency (job startup) and cost overhead. For small datasets, a Lambda might still be more efficient. But for large aggregations, Glue’s scale wins.</p>
</li>
<li>
<p><strong>Error Handling Strategy</strong>
Because failures can occur per container, tune retry policies on the Express children. Ensure idempotency so partial retries are safe. Also, design fallback or compensation logic (e.g. mark container as failed in DynamoDB and continue with others).</p>
</li>
<li>
<p><strong>State Transition Costs</strong>
Step Functions charges per state transition. Avoid overly fine-grained state machines, and batch work cleverly when possible to limit excessive transitions.</p>
</li>
<li>
<p><strong>Concurrency &amp; Rate Limits</strong>
Setting <code>MaxConcurrency</code> properly is crucial to avoid hitting API rate limits. You may need dynamic throttling or backoff logic if API limits vary per container.</p>
</li>
<li>
<p><strong>Monitoring &amp; Visibility</strong>
Combine Step Functions’ built-in execution view with DynamoDB logs and CloudWatch metrics. Use alarms for failed executions or excessive retries.</p>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="example-walkthrough">Example Walkthrough<a href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator#example-walkthrough" class="hash-link" aria-label="Direct link to Example Walkthrough" title="Direct link to Example Walkthrough" translate="no">​</a></h2>
<p>Here’s a hypothetical example run:</p>
<ol>
<li>
<p>Input includes 50 containers (e.g. locations) to process.</p>
</li>
<li>
<p>Parent orchestrator uses Distributed Map to launch 50 child executions, but only 5 run concurrently (due to <code>MaxConcurrency = 5</code>).</p>
</li>
<li>
<p>Each Express child:</p>
<ul>
<li>Calls an external API endpoint</li>
<li>If the API returns a <code>nextPageToken</code>, loops until pagination is exhausted</li>
<li>Writes each page’s data to <code>s3://bucket/job-123/containerX-pageY.json</code></li>
<li>Returns metadata: <code>{ "container": "X", "pages": 3, "s3Prefix": "job-123/containerX/" }</code></li>
</ul>
</li>
<li>
<p>After all children finish, the parent triggers Glue to read all partial JSONs under <code>job-123/</code>, merge them, and produce <code>job-123/final-output.json</code>.</p>
</li>
<li>
<p>The parent writes to DynamoDB: start time, end time, number of containers, number of records, success/failure, etc.</p>
</li>
<li>
<p>The caller or UI can query DynamoDB for job status, or review the merged output in S3 or downstream systems.</p>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="getting-started--deployment-guidance">Getting Started &amp; Deployment Guidance<a href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator#getting-started--deployment-guidance" class="hash-link" aria-label="Direct link to Getting Started &amp; Deployment Guidance" title="Direct link to Getting Started &amp; Deployment Guidance" translate="no">​</a></h2>
<p>Here are steps you can follow to try this pattern:</p>
<ol>
<li><strong>Clone the sample repo</strong> (linked in the PR) and examine the ASL definitions.</li>
<li><strong>Deploy the orchestration + children</strong> via CloudFormation or CDK.</li>
<li><strong>Write a Glue script</strong> that merges JSON / CSV parts — this can be minimal.</li>
<li><strong>Define your DynamoDB table</strong> schema (job metadata).</li>
<li><strong>Test locally with a small number of containers</strong> to validate pagination, S3 writes, and retries.</li>
<li><strong>Scale up and tune <code>MaxConcurrency</code></strong>, error policies, and Glue timeout.</li>
<li><strong>Add CloudWatch metrics / alarms / dashboards</strong> to monitor failures, retries, and throughput.</li>
</ol>
<p>You can also adapt parts:</p>
<ul>
<li>Swap Glue for Athena, Redshift, or Lambda-based merging</li>
<li>Use more advanced backoff or token-bucket throttling strategies</li>
<li>Add conditional branching (e.g. skip certain containers)</li>
<li>Extend error compensation logic (e.g. partial result salvage)</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://treadyaparna.github.io/blog/2025-10-10-distributed-data-stream-aggregator#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">​</a></h2>
<p>In this post, I’ve walked through a compelling, Lambda-less pattern for distributed data aggregation using AWS Step Functions, S3, Glue, and DynamoDB. By leveraging <strong>Distributed Map</strong> and offloading heavy work into managed services, you gain scalable, maintainable, and resilient workflows with less custom code.</p>
<p>This approach is ideal when your data per entity is large, your orchestration logic is complex, and you want to reduce Lambda sprawl. That said, always balance tradeoffs (Glue latency, Express durability, cost) and experiment with tuning.</p>
<p>👉 Explore the full implementation in the <a href="https://github.com/aws-samples/step-functions-workflows-collection/pull/404" target="_blank" rel="noopener noreferrer">GitHub pull request</a> and try it in your own workflows.</p>]]></content>
        <author>
            <name>Aparna Saha</name>
            <uri>https://www.linkedin.com/in/aparnasaha/</uri>
        </author>
        <category label="aws" term="aws"/>
        <category label="step-functions" term="step-functions"/>
        <category label="data-streaming" term="data-streaming"/>
        <category label="architecture" term="architecture"/>
    </entry>
</feed>