"use strict";(globalThis.webpackChunktreadyaparna_site=globalThis.webpackChunktreadyaparna_site||[]).push([[130],{7735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"2025-10-10-distributed-data-stream-aggregator","metadata":{"permalink":"/blog/2025-10-10-distributed-data-stream-aggregator","editUrl":"https://github.com/treadyaparna/treadyaparna.github.io/edit/main/blog/2025-10-10-distributed-data-stream-aggregator.md","source":"@site/blog/2025-10-10-distributed-data-stream-aggregator.md","title":"Distributed Data Stream Aggregator with AWS Step Functions","description":"A comprehensive Distributed Data Stream Aggregator workflow that demonstrates large-scale data aggregation from multiple third-party locations using AWS Step Functions\' distributed processing capabilities.","date":"2025-10-10T00:00:00.000Z","tags":[{"inline":false,"label":"aws","permalink":"/blog/tags/aws","description":"AWS Cloud"},{"inline":false,"label":"step-functions","permalink":"/blog/tags/step-functions","description":"Step Function Workflows"},{"inline":true,"label":"data-streaming","permalink":"/blog/tags/data-streaming"},{"inline":true,"label":"architecture","permalink":"/blog/tags/architecture"}],"readingTime":8.67,"hasTruncateMarker":true,"authors":[{"name":"Aparna Saha","title":"Senior Software Engineer","url":"https://www.linkedin.com/in/aparnasaha/","page":{"permalink":"/blog/authors/aparna"},"socials":{"linkedin":"https://www.linkedin.com/in/aparnasaha/","github":"https://github.com/treadyaparna"},"imageURL":"https://github.com/treadyaparna.png","key":"aparna"}],"frontMatter":{"slug":"2025-10-10-distributed-data-stream-aggregator","title":"Distributed Data Stream Aggregator with AWS Step Functions","authors":["aparna"],"tags":["aws","step-functions","data-streaming","architecture"]},"unlisted":false},"content":"A comprehensive **Distributed Data Stream Aggregator** workflow that demonstrates large-scale data aggregation from multiple third-party locations using AWS Step Functions\' distributed processing capabilities.\\n\\nA key highlight of this solution is its **unique no-Lambda approach**, making it a **low-code (almost no-code)** architecture \u2014 with minimal coding required only in the AWS Glue job for final consolidation.\x3c!--truncate--\x3e\\n\\n## Introduction\\n\\nWhen working at scale, coordinating the ingestion of data from many external APIs \u2014 with pagination, retries, rate limits, and large payloads \u2014 gets complicated fast. The typical solution often leans heavily on AWS Lambda, which brings its own operational and scaling burdens.\\n\\nThis post walks through a new, Lambda-free pattern contributed to the [AWS Step Functions Workflows Collection](https://github.com/aws-samples/step-functions-workflows-collection/pull/404): a **three-tier, distributed data aggregator** using Step Functions (standard + express), S3, Glue, and DynamoDB. You\u2019ll see how to orchestrate high fan-out, handle payload limits, and maintain observability \u2014 all with minimal custom code.\\n\\nI\u2019ll cover:\\n\\n* The overall architecture and rationale\\n* How each tier works (orchestrator, express children, aggregation)\\n* Key AWS Step Functions configurations (Distributed Map, concurrency, error handling)\\n* Tradeoffs, best practices, and when to use this pattern\\n\\nBy the end, you\u2019ll have a blueprint you can adapt for your own large-scale data-aggregation use cases.\\n\\n## Solution Overview & Motivation\\n\\n### The Problem Space\\n\\nSuppose you manage hundreds of locations or entities, and for each one you need to call multiple external APIs (each with pagination, retries, rate limits) and aggregate a combined dataset. You also expect that the result for a single location might exceed Step Functions\u2019 256 KB state payload limit (so you can\u2019t carry full results inline).\\n\\nMany teams solve this with a web of Lambda functions:\\n\\n1. Lambda A fans out tasks\\n2. Lambda B handles HTTP calls + pagination\\n3. Lambda C aggregates results\\n4. Etc.\\n\\nThis introduces more code, more error surfaces, and scaling headaches.\\n\\nWhat if you could move more logic into Step Functions itself, let AWS handle the orchestration, and offload heavy work to managed services (S3, Glue) \u2014 with **zero Lambda**?\\n\\nThat\u2019s exactly what this new workflow achieves.\\n\\n### Architecture at a Glance\\n\\n![Illustration](../assets/images/2025-10-01-distributed-data-stream-aggregator-illustration.png)\\n\\nHere\u2019s the high-level flow:\\n\\n```\\nOrchestrator (Step Functions \u2014 Standard)\\n  \u2514\u2500 Distributed Map (Iterate containers/tasks)\\n       \u2514\u2500 Express Child Workflows (API calls, pagination, partial writes to S3)\\nAfter all children finish:\\n  \u2514\u2500 Glue Job (merge partial S3 files)\\n  \u2514\u2500 Update DynamoDB (status, counts, metadata)\\n```\\n\\n* The **orchestrator** acts as the parent state machine (Standard mode).\\n* It uses **Distributed Map** to iterate over \u201ccontainers\u201d (e.g. location or entity).\\n* For each item, an **Express child state machine** is invoked to perform HTTP API calls, pagination, and write partial results to S3.\\n* Once all child executions complete, the orchestrator triggers a **Glue job** to merge partial outputs into a final consolidated dataset.\\n* A **DynamoDB table** tracks status, metrics, and metadata.\\n\\nBecause partial results live in S3 (not in Step Functions\u2019 state), I avoid payload size limits and keep orchestration logic lightweight.\\n\\n## How It Works: Step by Step\\n\\nLet\u2019s dive into each part of the workflow in more detail, along with key configurations.\\n\\n### 1. Parent Orchestrator + Distributed Map\\n\\nThe parent state machine is implemented in **Standard** Step Functions mode. Its key job is to fan out work using a **Distributed Map** state. Because I adopt the distributed mode, the state machine does *not* manage all iterations internally \u2014 that offloads scale to AWS.\\n\\nHere\u2019s a representative snippet:\\n\\n```json\\n{\\n  \\"Type\\": \\"Map\\",\\n  \\"Label\\": \\"IterateContainers\\",\\n  \\"ItemProcessor\\": {\\n    \\"ProcessorConfig\\": {\\n      \\"Mode\\": \\"DISTRIBUTED\\"\\n    }\\n  },\\n  \\"MaxConcurrency\\": 5,\\n  \\"ItemSelector\\": {\\n    \\"container.$\\": \\"$.container\\"\\n  },\\n  \\"Iterator\\": {\\n    \\"StartAt\\": \\"StartExpressChild\\",\\n    ...\\n  }\\n}\\n```\\n\\n* `Mode: DISTIBUTED` tells Step Functions to spawn independent child executions per item.\\n* `MaxConcurrency` (e.g. set to 5) throttles how many child executions run in parallel, helping avoid overwhelming external APIs.\\n* Each child receives one \u201ccontainer\u201d item (e.g. a location or entity) to process.\\n\\nAfter the Map completes, the parent moves on to aggregation and status update steps (e.g. calling Glue, writing to DynamoDB).\\n\\n### 2. Express Child Workflows: Data Fetch & Pagination\\n\\nEach Express child workflow is responsible for:\\n\\n* Making HTTP (or other) API calls\\n* Handling pagination (if the API returns a \u201cnext page\u201d token)\\n* Retrying on transient errors (with exponential backoff)\\n* Writing partial results to S3\\n* Returning a small summary to the parent\\n\\nBecause Express workflows are lightweight and ephemeral, they\u2019re ideal for short-lived data-fetch tasks. But because they\u2019re \u201cexpress\u201d, they don\u2019t offer exactly the same durability guarantees as Standard \u2014 so design accordingly (e.g. idempotency, retries, monitoring).\\n\\nA simplified flow inside an Express child might look like:\\n\\n1. Call API endpoint\\n2. Check for `nextPageToken`\\n\\n   * If yes, loop / re-enter the state\\n   * If no, finish\\n3. Accumulate or write result chunk(s) to S3\\n4. Return a small metadata payload (e.g. record count, S3 key)\\n\\nBecause full datasets for a container may be large, the child never returns full data in the Step Functions state. Instead, it writes into S3 \u2014 e.g. `s3://bucket/jobID/containerX.json`.\\n\\n### 3. Aggregation via Glue\\n\\nOnce all Express children complete, the orchestrator triggers an AWS Glue job. Its responsibility:\\n\\n* Scan the \u201cjob prefix\u201d in S3 (e.g. `s3://bucket/jobID/`)\\n* Read all partial files\\n* Merge / union them into a final dataset\\n* Write out a consolidated result (e.g. JSON, Parquet, CSV)\\n\\nThis offloads heavy merging/aggregation out of Step Functions and into Glue, which is built for data processing scale.\\n\\n### 4. Status Tracking with DynamoDB\\n\\nParallel to Glue, or after Glue completes, orchestrator writes execution metadata into a **DynamoDB** table. Fields typically include:\\n\\n* Job ID\\n* Start / end timestamps\\n* Number of containers processed\\n* Number of records aggregated\\n* Status (succeeded / failed / partial)\\n* Retry counters or error messages\\n\\nThis gives you an external, queryable log of workflow runs beyond the Step Functions execution history.\\n\\n## Why This Pattern Matters\\n\\nLet\u2019s compare this approach to a more traditional Lambda-centric pattern, and see why this might be a better fit in many cases.\\n\\n| Challenge / Constraint  | Traditional Lambda-Driven Approach               | This No-Lambda Distributed Pattern                                 |\\n| ----------------------- | ------------------------------------------------ | ------------------------------------------------------------------ |\\n| Payload size limits     | Often need to chunk or stream through Lambda     | Results are stored in S3, not carried in state                     |\\n| Lambda code maintenance | You write and maintain dozens of functions       | Minimal or zero custom code (just config + glue script)            |\\n| Scaling & orchestration | You must manage concurrency, cold starts         | Step Functions + Distributed Map abstracts much orchestration      |\\n| Fault isolation         | Failures in one Lambda might affect others       | Each child is isolated; individual retries possible                |\\n| Cost model              | You pay for Lambda execution time per invocation | You pay for state transitions, Glue job, and S3 access             |\\n| Observability           | You need to build logging/tracing across Lambdas | Step Functions gives built-in visibility; DynamoDB logs augment it |\\n\\nThis pattern is especially suited when:\\n\\n* You have **many entities or containers** to fetch in parallel\\n* Data per container can be large (bigger than 256 KB)\\n* You prefer **infrastructure as configuration** over custom code\\n* You want to minimize the Lambda surface area\\n\\nThat said, it\u2019s not a silver bullet \u2014 which leads us to tradeoffs and things to watch out for.\\n\\n\\n## Tradeoffs & Design Considerations\\n\\n1. **Express vs Standard Workflows**\\n   Express workflows are fast and cost-efficient, but with lower execution duration and less durability guarantees. If your data fetch tasks are long-running or mission-critical, consider Standard children (though that complicates concurrency and cost).\\n\\n2. **Glue Cold Starts and Overheads**\\n   Glue adds latency (job startup) and cost overhead. For small datasets, a Lambda might still be more efficient. But for large aggregations, Glue\u2019s scale wins.\\n\\n3. **Error Handling Strategy**\\n   Because failures can occur per container, tune retry policies on the Express children. Ensure idempotency so partial retries are safe. Also, design fallback or compensation logic (e.g. mark container as failed in DynamoDB and continue with others).\\n\\n4. **State Transition Costs**\\n   Step Functions charges per state transition. Avoid overly fine-grained state machines, and batch work cleverly when possible to limit excessive transitions.\\n\\n5. **Concurrency & Rate Limits**\\n   Setting `MaxConcurrency` properly is crucial to avoid hitting API rate limits. You may need dynamic throttling or backoff logic if API limits vary per container.\\n\\n6. **Monitoring & Visibility**\\n   Combine Step Functions\u2019 built-in execution view with DynamoDB logs and CloudWatch metrics. Use alarms for failed executions or excessive retries.\\n\\n## Example Walkthrough\\n\\nHere\u2019s a hypothetical example run:\\n\\n1. Input includes 50 containers (e.g. locations) to process.\\n2. Parent orchestrator uses Distributed Map to launch 50 child executions, but only 5 run concurrently (due to `MaxConcurrency = 5`).\\n3. Each Express child:\\n\\n   * Calls an external API endpoint\\n   * If the API returns a `nextPageToken`, loops until pagination is exhausted\\n   * Writes each page\u2019s data to `s3://bucket/job-123/containerX-pageY.json`\\n   * Returns metadata: `{ \\"container\\": \\"X\\", \\"pages\\": 3, \\"s3Prefix\\": \\"job-123/containerX/\\" }`\\n4. After all children finish, the parent triggers Glue to read all partial JSONs under `job-123/`, merge them, and produce `job-123/final-output.json`.\\n5. The parent writes to DynamoDB: start time, end time, number of containers, number of records, success/failure, etc.\\n6. The caller or UI can query DynamoDB for job status, or review the merged output in S3 or downstream systems.\\n\\n## Getting Started & Deployment Guidance\\n\\nHere are steps you can follow to try this pattern:\\n\\n1. **Clone the sample repo** (linked in the PR) and examine the ASL definitions.\\n2. **Deploy the orchestration + children** via CloudFormation or CDK.\\n3. **Write a Glue script** that merges JSON / CSV parts \u2014 this can be minimal.\\n4. **Define your DynamoDB table** schema (job metadata).\\n5. **Test locally with a small number of containers** to validate pagination, S3 writes, and retries.\\n6. **Scale up and tune `MaxConcurrency`**, error policies, and Glue timeout.\\n7. **Add CloudWatch metrics / alarms / dashboards** to monitor failures, retries, and throughput.\\n\\nYou can also adapt parts:\\n\\n* Swap Glue for Athena, Redshift, or Lambda-based merging\\n* Use more advanced backoff or token-bucket throttling strategies\\n* Add conditional branching (e.g. skip certain containers)\\n* Extend error compensation logic (e.g. partial result salvage)\\n\\n## Conclusion\\n\\nIn this post, I\u2019ve walked through a compelling, Lambda-less pattern for distributed data aggregation using AWS Step Functions, S3, Glue, and DynamoDB. By leveraging **Distributed Map** and offloading heavy work into managed services, you gain scalable, maintainable, and resilient workflows with less custom code.\\n\\nThis approach is ideal when your data per entity is large, your orchestration logic is complex, and you want to reduce Lambda sprawl. That said, always balance tradeoffs (Glue latency, Express durability, cost) and experiment with tuning.\\n\\n\ud83d\udc49 Explore the full implementation in the [GitHub pull request](https://github.com/aws-samples/step-functions-workflows-collection/pull/404) and try it in your own workflows."}]}}')}}]);